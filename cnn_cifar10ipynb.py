# -*- coding: utf-8 -*-
"""CiFAR.10ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OWdioPU6sNPq-PdaP6ojCCUtws0N8HPD
"""

#배치사이즈를 뺐어


import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

import sys
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten,BatchNormalization
from keras.layers.convolutional import Conv2D, MaxPooling2D
import numpy as np 
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.datasets import cifar10   #111
from matplotlib import pyplot



print('Python version : ', sys.version)
print('Keras version : ', keras.__version__)

img_rows = 32   #111
img_cols = 32



(x_train, y_train), (x_test, y_test) =cifar10.load_data()   #111

input_shape = (img_rows, img_cols,3)
x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)     #1111
x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

from keras.utils import np_utils


## 원-핫 인코딩
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
num_classes = y_test.shape[1]

filename='checkpoint.h5'.format(epochs)


num_classes = 10
epochs = 250
early_stopping=EarlyStopping(monitor='val_loss',mode='min',patience=15,verbose=1)                           #얼리스타핑
checkpoint=ModelCheckpoint(filename,monitor='val_loss',verbose=1,save_best_only=True,mode='auto')           #체크포인트



model = Sequential()
#1
model.add(Conv2D(64, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
model.add(Dropout(0.25))
#4
model.add(Flatten())
model.add(Dense(1000, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))
model.summary()

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=epochs, verbose=1, validation_data=(x_test, y_test),callbacks=[checkpoint,early_stopping]) #학습

score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:',  score[0])
print('Test accuracy:', score[1])